{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "solar-parish",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/jax/_src/lib/__init__.py:32: UserWarning: JAX on Mac ARM machines is experimental and minimally tested. Please see https://github.com/google/jax/issues/5501 in the event of problems.\n",
      "  warnings.warn(\"JAX on Mac ARM machines is experimental and minimally tested. \"\n"
     ]
    }
   ],
   "source": [
    "import jax.numpy as jnp\n",
    "from jax import grad, vmap, jit, random, value_and_grad,vjp\n",
    "import jax.nn as nn\n",
    "import tqdm\n",
    "\n",
    "\n",
    "from scipy.ndimage.interpolation import shift\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab002e14",
   "metadata": {},
   "source": [
    "### RNN using Jax?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f17c7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import haiku as hk\n",
    "import jax\n",
    "import optax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f97c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mso(samples,horizon=12):\n",
    "    t=jnp.arange(0,samples)\n",
    "    X=jnp.sin(0.2*t)+jnp.sin(0.311*t)+jnp.sin(0.42*t)+jnp.sin(0.51*t)\n",
    "    y=shift(X,horizon)\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8272a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y=mso(25000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7acecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn_forward(x_t,h_prev,hidden_size=32):\n",
    "    f=hk.VanillaRNN(hidden_size=hidden_size)\n",
    "    h_t,h_t=f(x_t,h_prev)\n",
    "    g=hk.Linear(1)\n",
    "    y_t=nn.relu(g(h_t))\n",
    "    return y_t,h_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e74dc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_forward_pure=hk.without_apply_rng(hk.transform(rnn_forward))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7102d72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "key=random.PRNGKey(0)\n",
    "params=rnn_forward_pure.init(key,jnp.array([1.0]),jnp.array([1.0]*32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a13114",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_loss_fn(params,X,y,t):\n",
    "    \"\"\"\n",
    "    X: input timeseries\n",
    "    y: output timeseries\n",
    "    t: timestep to calculate the loss\n",
    "    \"\"\"\n",
    "    h_t=jnp.array([0.0]*32)\n",
    "    for i in range(t):\n",
    "        x_t=X[np.array([t])]\n",
    "        y_t_pred,h_t=rnn_forward_pure.apply(params,x_t,h_t)\n",
    "    y_t=y[np.array([t-12])]\n",
    "    mse_loss=((y_t_pred-y_t)**2).sum()\n",
    "    return mse_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc65c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optax.adam(0.01)\n",
    "opt_state = optimizer.init(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab489ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets design our training loop\n",
    "h_t=jnp.array([0.0]*32) #The initial state of the RNN\n",
    "for t in tqdm.tqdm(range(X.shape[0])):\n",
    "    x_t=X[np.array([t])]\n",
    "    if t>=12: \n",
    "        loss,dy_dparam=value_and_grad(naive_loss_fn)(params,X,y,t)\n",
    "        updates, opt_state = optimizer.update(dy_dparam, opt_state)\n",
    "        params=optax.apply_updates(params,updates)\n",
    "        print(loss.block_until_ready())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11c5da6",
   "metadata": {},
   "source": [
    "### Problems with the naive implementation?\n",
    "- We need to unroll the entirity of input until the time step 0 to calculate loss at time t\n",
    "- Gradient calculation time increases as t increases\n",
    "- Batch implementation is tricky as we cant parallize this array \n",
    "\n",
    "Properties we want to have our P_RNN to have:\n",
    "- forward function that takes params, hidden_state, input -> hidden_state\n",
    "- sensitivity function that takes params, hidden_state, p - (input,hidden_state) trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0b2f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn_forward(i_t,h_tminus1,hidden_size=32):\n",
    "    f=hk.VanillaRNN(hidden_size=hidden_size)\n",
    "    h_t,h_t=f(i_t,h_tminus1)\n",
    "    return h_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b155eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_forward_pure=hk.without_apply_rng(hk.transform(rnn_forward))\n",
    "key=random.PRNGKey(0)\n",
    "rnn_params=rnn_forward_pure.init(key,jnp.array([1.0]),jnp.array([1.0]*32))\n",
    "rnn_forward_pure_jit=rnn_forward_pure.apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a79ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sensitivity(rnn_params,hidden_state,rnn_trajectory):\n",
    "    inputs,hidden_states=rnn_trajectory[0],rnn_trajectory[1]\n",
    "    rnn_jac_theta=jax.jacrev(rnn_forward_pure.apply)\n",
    "    rnn_jac_hidden=jax.jacrev(rnn_forward_pure.apply,argnums=2)\n",
    "    del_h_tminus1_theta=rnn_jac_theta(rnn_params,inputs[0],hidden_states[0])\n",
    "    del_h_t_theta=del_h_tminus1_theta\n",
    "    \n",
    "    def sensitivity_calc(del_h_tminus1_theta,trajectory):\n",
    "        i_t,h_tminus1=trajectory\n",
    "        del_f_theta=rnn_jac_theta(rnn_params,i_t,h_tminus1)\n",
    "        del_f_h_tminus1=rnn_jac_hidden(rnn_params,i_t,h_tminus1)\n",
    "        # del_h_t_theta=del_f_h_tminus1*del_h_tminus1_theta\n",
    "        del_h_t_theta= jax.tree_map(lambda x: jnp.tensordot(del_f_h_tminus1,x,axes=1), del_h_tminus1_theta) \n",
    "        # del_h_t_theta+=del_f_theta\n",
    "        del_h_t_theta=jax.tree_multimap(lambda x, y: x+y, del_h_t_theta, del_f_theta)\n",
    "        return del_h_t_theta,None\n",
    "    \n",
    "    if len(rnn_trajectory)>1:\n",
    "        del_h_t_theta,_=jax.lax.scan(sensitivity_calc,del_h_tminus1_theta,(inputs[1:],hidden_states[1:]))\n",
    "    return del_h_t_theta\n",
    "#sensitivity=jit(sensitivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369b1a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "truncation=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af803045",
   "metadata": {},
   "outputs": [],
   "source": [
    "def g(h_t):\n",
    "    out=nn.relu(hk.Linear(32)(h_t))\n",
    "    out=hk.Linear(1)(out)\n",
    "    return out\n",
    "\n",
    "g=hk.without_apply_rng(hk.transform(g))\n",
    "g_params=g.init(key,jnp.array([1.0]*32))\n",
    "\n",
    "def loss_fn(g_params,h_t,y_t):\n",
    "    y_t_pred=g.apply(g_params,h_t)\n",
    "    return ((y_t_pred-y_t)**2).sum()\n",
    "\n",
    "loss_fn=jit(loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fa23b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_rnn = optax.adam(0.0001)\n",
    "opt_state_rnn = optimizer_rnn.init(rnn_params)\n",
    "optimizer_g = optax.adam(0.001)\n",
    "opt_state_g = optimizer_g.init(g_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00af4cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_tminus1=jnp.array([0.0]*32) #The initial state of the RNN\n",
    "trajectories=[jnp.zeros((truncation,1)),jnp.zeros((truncation,32))]\n",
    "\n",
    "def update_trajectories(trajectories,i,h):\n",
    "    trajectories[0]=jnp.concatenate((trajectories[0][1:],i.reshape(1,-1)),axis=0)\n",
    "    trajectories[1]=jnp.concatenate((trajectories[1][1:],h.reshape(1,-1)),axis=0)\n",
    "    return trajectories\n",
    "    \n",
    "losses=[]\n",
    "for epoch in range(10):\n",
    "    for t in tqdm.tqdm(range(X.shape[0])):\n",
    "        x_t,y_t=X[np.array([t])],y[np.array([t])]\n",
    "        #Update trajectories\n",
    "        trajectories=update_trajectories(trajectories,x_t,h_tminus1)\n",
    "        h_t=rnn_forward_pure_jit(rnn_params,x_t,h_tminus1)\n",
    "        #Predict the output and get the loss\n",
    "        loss,grad_g_params=value_and_grad(loss_fn)(g_params,h_t,y_t)\n",
    "        #Calculate the gradient wrt to rnn_params using the sensitivities of the rnn and g layers\n",
    "        rnn_sensitivity_t=sensitivity(rnn_params,h_t,trajectories)\n",
    "        g_sensitivity_t=jax.jacfwd(loss_fn,argnums=1)(g_params,h_t,y_t)\n",
    "        grad_rnn_params=jax.tree_multimap(lambda x: jnp.tensordot(g_sensitivity_t,x,axes=1), rnn_sensitivity_t) \n",
    "        #Update the gradients\n",
    "        updates, opt_state_rnn = optimizer_rnn.update(grad_rnn_params, opt_state_rnn)\n",
    "        rnn_params=optax.apply_updates(rnn_params,updates)\n",
    "        updates, opt_state_g = optimizer_g.update(grad_g_params, opt_state_g)\n",
    "        g_params=optax.apply_updates(g_params,updates)\n",
    "        #Calculate average loss and print if it is print frequency\n",
    "        losses.append(loss)\n",
    "        if len(losses)==100:\n",
    "            print(\"Loss: \",np.mean(losses))\n",
    "            losses=[]\n",
    "        h_tminus1=h_t #Previous state becomes the current state before the next iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1253d93",
   "metadata": {},
   "source": [
    "Awesome! It works, and its super fast too! Let's do some sanity check for the sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093e3129",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_x=X[0:20]\n",
    "\n",
    "h_t=jnp.array([0.0]*32)\n",
    "def test_sensitivity(rnn_params,sample_x,h_t):\n",
    "    for i in range(20):\n",
    "        h_t=rnn_forward_pure_jit(rnn_params,sample_x[np.array([i])],h_t)\n",
    "    return h_t\n",
    "\n",
    "true_sensitivity=jax.jacrev(test_sensitivity)(rnn_params,sample_x,h_tminus1)\n",
    "\n",
    "hidden_states=[]\n",
    "for i in range(20):\n",
    "    hidden_states.append(h_t)\n",
    "    h_t=rnn_forward_pure_jit(rnn_params,sample_x[np.array([i])],h_t)\n",
    "print(\"Hidden state calculated correctly: \",jnp.allclose(h_t,test_sensitivity(rnn_params,sample_x,h_tminus1)))\n",
    "hidden_states=jnp.stack(hidden_states)\n",
    "our_sensitivity=sensitivity(rnn_params,None,[sample_x.reshape(-1,1),hidden_states])\n",
    "print(\"Sensitivity calculated correctly: \",jnp.allclose(true_sensitivity['vanilla_rnn/linear']['w'],our_sensitivity['vanilla_rnn/linear']['w'],atol=0.0001))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395242a7",
   "metadata": {},
   "source": [
    "Next Step? create a haiku model that can be transformed, it automatically manages state and is differentiable with grad\n",
    "\n",
    "Notes:\n",
    "1. Maybe we should use haiku states\n",
    "2. trajectories is updated in forward pass as a state variable\n",
    "3. .apply is differentiable, and should use the trajectories to calculate sensitivities internally"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68477e71",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbb8b877",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c606873f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.rnn import MultiplicativeRNN,rnn_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdfed2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94b7fb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn_forward(obs,act,last_state):\n",
    "    rnn=MultiplicativeRNN(10,4,32)\n",
    "    out,state=rnn((obs,act),last_state)\n",
    "    return out,state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb0ce534",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_forward_pure=hk.without_apply_rng(hk.transform(rnn_forward))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599b0164",
   "metadata": {},
   "outputs": [],
   "source": [
    "key=random.PRNGKey(0)\n",
    "sample_o=jax.random.normal(key,[20,10])\n",
    "sample_a=jax.random.normal(key,[20,4])\n",
    "\n",
    "h_t=MultiplicativeRNN.initial_state(10,4,32,50)\n",
    "rnn_params=rnn_forward_pure.init(key,sample_o[0],sample_a[0],h_t)\n",
    "def test_sensitivity(rnn_params,sample_o,sample_a,h_t):\n",
    "    for i in range(10):\n",
    "        out,h_t=(rnn_forward_pure.apply)(rnn_params,sample_o[i],sample_a[i],h_t)\n",
    "    return out\n",
    "\n",
    "true_sensitivity=jax.jacrev(test_sensitivity)(rnn_params,sample_o,sample_a,h_t)\n",
    "out_true=test_sensitivity(rnn_params,sample_o,sample_a,h_t).block_until_ready()\n",
    "h_t=MultiplicativeRNN.initial_state(10,4,32,50)\n",
    "hidden_states=[]\n",
    "for i in range(10):\n",
    "    out,h_t=rnn_forward_pure.apply(rnn_params,sample_o[i],sample_a[i],h_t)\n",
    "\n",
    "print(\"Hidden state calculated correctly: \",jnp.allclose(out,out_true,atol=0.01))\n",
    "our_sensitivity=MultiplicativeRNN.sensitivity(rnn_forward_pure.apply,rnn_params,h_t)\n",
    "print(\"Sensitivity calculated correctly: \",jnp.allclose(true_sensitivity['multiplicative_rnn']['w_h'],\n",
    "                                                        our_sensitivity['multiplicative_rnn']['w_h'],atol=0.0001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8768eac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_forward_pure_apply=custom_jvp(rnn_forward_pure.apply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba6fd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_forward_pure_apply(params,obs,act,(last_hidden_state,None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59095f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_forward_pure_apply2=hk.without_apply_rng(hk.transform(rnn_forward)).apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cf7ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import custom_jvp\n",
    "import jax.numpy as jnp\n",
    "\n",
    "# f :: a -> b\n",
    "def sensitivity(rnn_params,rnn_state):\n",
    "        \"\"\"Returns the jacobian of the current hidden state with respect to the RNN params \n",
    "            until the length of the trajectory. \n",
    "\n",
    "            In future this will be replaced with with JAX grad primitives\n",
    "        Args:\n",
    "            rnn_forward_pure ([type]): Pure haiku RNN transformed function \n",
    "            rnn_params ([type]): RNN parameters for the transformed function\n",
    "            rnn_trajectory (tuple(jnp.array,jnp.array)): Tuple of (inputs,last hidden_state)\n",
    "\n",
    "        Returns:\n",
    "            jax.numpy.array: Tensor containing the sensitivities as a Jacobian matrix\n",
    "        \"\"\"\n",
    "        hidden_state,trajectory=rnn_state\n",
    "        last_hidden_states=trajectory.last_hidden_states\n",
    "        observations=trajectory.observations\n",
    "        last_actions=trajectory.last_actions\n",
    "        \n",
    "        def rnn_forward_out(params,obs, act,last_hidden_state):\n",
    "            out,_=rnn_forward_pure_apply2(params,obs,act,(last_hidden_state,None))\n",
    "            return out #We do not need the state output hence we do this trick \n",
    "\n",
    "\n",
    "        rnn_jac_theta=jax.jacrev(rnn_forward_out)\n",
    "        rnn_jac_hidden=jax.jacrev(rnn_forward_out,argnums=3)\n",
    "        del_h_tminus1_theta=rnn_jac_theta(rnn_params,observations[0],last_actions[0],last_hidden_states[0])\n",
    "        del_h_t_theta=del_h_tminus1_theta\n",
    "\n",
    "        def sensitivity_calc(del_h_tminus1_theta,trajectory):\n",
    "            o_t,a_tminus1,h_tminus1=trajectory\n",
    "            del_f_theta=rnn_jac_theta(rnn_params,o_t,a_tminus1,h_tminus1)\n",
    "            del_f_h_tminus1=rnn_jac_hidden(rnn_params,o_t,a_tminus1,h_tminus1)\n",
    "            # del_h_t_theta=del_f_h_tminus1*del_h_tminus1_theta\n",
    "            del_h_t_theta= jax.tree_map(lambda x: jnp.tensordot(del_f_h_tminus1,x,axes=1), del_h_tminus1_theta) \n",
    "            # del_h_t_theta+=del_f_theta\n",
    "            del_h_t_theta=jax.tree_multimap(lambda x, y: x+y, del_h_t_theta, del_f_theta)\n",
    "            return del_h_t_theta,None\n",
    "        \n",
    "        del_h_t_theta,_=jax.lax.scan(sensitivity_calc,del_h_tminus1_theta,(observations[1:],last_actions[1:],\n",
    "                                                                               last_hidden_states[1:]))\n",
    "        return del_h_t_theta\n",
    "    \n",
    "def f_jvp(primals, tangents):\n",
    "    rnn_params,o_t,a_t,h_tminus1=primals\n",
    "    rnn_params_t,o_t_t,a_t_t,h_tminus1_t=tangents\n",
    "    print(rnn_params_t['multiplicative_rnn']['w_h'])\n",
    "    primal_out=rnn_forward_pure.apply(rnn_params,o_t,a_t,h_tminus1)\n",
    "    jacobian=sensitivity(rnn_params,primal_out[1])\n",
    "    tangent_out=jax.tree_multimap(lambda x, y: jnp.tensordot(x,y,y.ndim), jacobian, rnn_params_t)\n",
    "    tangent_out=jnp.stack(jax.tree_util.tree_flatten(tangent_out)[0],axis=0).sum(axis=0)\n",
    "    return primal_out,(tangent_out,primal_out[1])\n",
    "\n",
    "rnn_forward_pure_apply.defjvp(f_jvp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8659a0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "key=random.PRNGKey(0)\n",
    "sample_o=jax.random.normal(key,[20,10])\n",
    "sample_a=jax.random.normal(key,[20,4])\n",
    "h_t=MultiplicativeRNN.initial_state(10,4,32,4)\n",
    "rnn_params=rnn_forward_pure.init(key,sample_o[0],sample_a[0],h_t)\n",
    "def test_sensitivity(rnn_params,sample_o,sample_a,h_t):\n",
    "    for i in range(10):\n",
    "        out,h_t=(rnn_forward_pure.apply)(rnn_params,sample_o[i],sample_a[i],h_t)\n",
    "    return out\n",
    "\n",
    "true_sensitivity=jax.jacrev(test_sensitivity)(rnn_params,sample_o,sample_a,h_t)\n",
    "out_true=test_sensitivity(rnn_params,sample_o,sample_a,h_t).block_until_ready()\n",
    "\n",
    "h_t=MultiplicativeRNN.initial_state(10,4,32,4)\n",
    "rnn_params=rnn_forward_pure.init(key,sample_o[0],sample_a[0],h_t)\n",
    "def test_sensitivity(rnn_params,sample_o,sample_a,h_t):\n",
    "    for i in range(10):\n",
    "        out,h_t=(rnn_forward_pure_apply)(rnn_params,sample_o[i],sample_a[i],h_t)\n",
    "    return out\n",
    "our_sensitivity=jax.jacrev(test_sensitivity)(rnn_params,sample_o,sample_a,h_t)\n",
    "out=test_sensitivity(rnn_params,sample_o,sample_a,h_t).block_until_ready()\n",
    "\n",
    "print(\"Hidden state calculated correctly: \",jnp.allclose(out,out_true,atol=0.01))\n",
    "print(\"Sensitivity calculated correctly: \",jnp.allclose(true_sensitivity['multiplicative_rnn']['w_h'],\n",
    "                                                        our_sensitivity['multiplicative_rnn']['w_h'],atol=0.0001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4a608f",
   "metadata": {},
   "outputs": [],
   "source": [
    "jit_fn=jit(jax.jacrev(trf.apply))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac852e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad39e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "start=time.time()\n",
    "our_sensitivity=MultiplicativeRNN.sensitivity(rnn_forward_pure.apply,rnn_params,h_t)\n",
    "print(time.time()-start)\n",
    "start=time.time()\n",
    "our_sensitivity=jit_fn(rnn_params,(sample_o,sample_a),h_t)\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b79cc19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trf=rnn_transform(MultiplicativeRNN,10,4,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "554c2ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden state calculated correctly:  True\n",
      "Sensitivity calculated correctly:  True\n"
     ]
    }
   ],
   "source": [
    "key=random.PRNGKey(0)\n",
    "sample_o=jax.random.normal(key,[20,10])\n",
    "sample_a=jax.random.normal(key,[20,4])\n",
    "h_t=MultiplicativeRNN.initial_state(10,4,32,50)\n",
    "rnn_params=rnn_forward_pure.init(key,sample_o[0],sample_a[0],h_t)\n",
    "def test_sensitivity(rnn_params,sample_o,sample_a,h_t):\n",
    "    for i in range(10):\n",
    "        out,h_t=(rnn_forward_pure.apply)(rnn_params,sample_o[i],sample_a[i],h_t)\n",
    "    return out\n",
    "\n",
    "true_sensitivity=jax.jacrev(test_sensitivity)(rnn_params,sample_o,sample_a,h_t)\n",
    "out_true=test_sensitivity(rnn_params,sample_o,sample_a,h_t).block_until_ready()\n",
    "\n",
    "h_t=MultiplicativeRNN.initial_state(10,4,32,50)\n",
    "rnn_params=rnn_forward_pure.init(key,sample_o[0],sample_a[0],h_t)\n",
    "h_tminus1=None\n",
    "for i in range(10):\n",
    "    h_tminus1=h_t\n",
    "    out,h_t=(trf.apply)(rnn_params,(sample_o[i],sample_a[i]),h_t)\n",
    "our_sensitivity=jax.jacrev(trf.apply)(rnn_params,(sample_o[9],sample_a[9]),h_tminus1)[0]\n",
    "out=test_sensitivity(rnn_params,sample_o,sample_a,h_t).block_until_ready()\n",
    "\n",
    "print(\"Hidden state calculated correctly: \",jnp.allclose(out,out_true,atol=0.01))\n",
    "print(\"Sensitivity calculated correctly: \",jnp.allclose(true_sensitivity['multiplicative_rnn']['w_h'],\n",
    "                                                        our_sensitivity['multiplicative_rnn']['w_h'],atol=0.0001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78946059",
   "metadata": {},
   "outputs": [],
   "source": [
    "our_sensitivity['multiplicative_rnn']['w_h']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb85d88",
   "metadata": {},
   "source": [
    "GOOD JOB!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
